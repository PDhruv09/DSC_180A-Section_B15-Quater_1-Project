{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0902d718",
   "metadata": {},
   "source": [
    "# Differentially Private Telemetry Data Analysis – Non-Private Exploration\n",
    "\n",
    "This notebook performs **non-private preprocessing and exploratory analysis** on the synthetic telemetry dataset.\n",
    "\n",
    "It covers:\n",
    "- Loading the raw telemetry CSV\n",
    "- Preprocessing (cleaning text, parsing timestamps, adding time features)\n",
    "- Computing event frequencies\n",
    "- Computing error rates and z-scores by product type\n",
    "- Visualizing key distributions and time trends\n",
    "\n",
    "These results serve as the **ground truth** for later differential privacy experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Use a simple matplotlib style\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# PATH SETUP\n",
    "# ----------------------------------------------------\n",
    "# This notebook assumes the following repo structure:\n",
    "#   <repo_root>/\n",
    "#       data/\n",
    "#           raw/\n",
    "#               synthetic_telemetry_data.csv\n",
    "#           processed/\n",
    "#       reports/\n",
    "#       visuals/\n",
    "#       notebooks/\n",
    "#\n",
    "# If your directories are different, update RAW_DIR, PROC_DIR,\n",
    "# REPORT_DIR, and VIS_DIR accordingly.\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Detect project root:\n",
    "# - If we are inside notebooks/, go one level up.\n",
    "# - Otherwise, use current working directory as root.\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "else:\n",
    "    ROOT_DIR = os.getcwd()\n",
    "\n",
    "# RAW_DIR: folder where the original CSV lives (change if different)\n",
    "RAW_DIR = os.path.join(ROOT_DIR, \"data\", \"raw\")\n",
    "\n",
    "# PROC_DIR: folder to store cleaned / processed data\n",
    "PROC_DIR = os.path.join(ROOT_DIR, \"data\", \"processed\")\n",
    "\n",
    "# REPORT_DIR: folder where summary tables (CSV/JSON) will be saved\n",
    "REPORT_DIR = os.path.join(ROOT_DIR, \"reports\")\n",
    "\n",
    "# VIS_DIR: folder where plots (PNG) will be saved\n",
    "VIS_DIR = os.path.join(ROOT_DIR, \"visuals\")\n",
    "\n",
    "# Make sure the output folders exist\n",
    "os.makedirs(PROC_DIR, exist_ok=True)\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "# RAW_PATH: path to the raw telemetry CSV file.\n",
    "# If your file has a different name or location, change it here.\n",
    "RAW_PATH = os.path.join(RAW_DIR, \"synthetic_telemetry_data.csv\")\n",
    "\n",
    "# CLEAN_PATH: path where the cleaned CSV will be saved.\n",
    "CLEAN_PATH = os.path.join(PROC_DIR, \"telemetry_clean.csv\")\n",
    "\n",
    "ROOT_DIR, RAW_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905db088",
   "metadata": {},
   "source": [
    "## 1. Load Raw Telemetry Data\n",
    "\n",
    "We start from the raw synthetic telemetry CSV provided by the instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# We load the raw synthetic telemetry file from RAW_PATH.\n",
    "# If this fails, double-check that:\n",
    "#   - RAW_PATH points to the correct folder/file\n",
    "#   - The file name matches exactly (including extension).\n",
    "# ----------------------------------------------------\n",
    "\n",
    "raw_df = pd.read_csv(RAW_PATH)\n",
    "print(f\"Raw shape: {raw_df.shape}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f49535",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Steps:\n",
    "1. Strip whitespace from `Product Type`, `Event Type`, and `User ID`.\n",
    "2. Parse `Time of Event` as a proper datetime.\n",
    "3. Drop rows with invalid timestamps.\n",
    "4. Create time-based features:\n",
    "   - `event_date`\n",
    "   - `event_hour`\n",
    "   - `event_dow`\n",
    "   - `is_weekend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "#   - Clean strings for Product Type, Event Type, User ID\n",
    "#   - Parse Time of Event into a datetime\n",
    "#   - Drop rows with invalid timestamps\n",
    "#   - Add time-based features:\n",
    "#         event_date  (date)\n",
    "#         event_hour  (0–23)\n",
    "#         event_dow   (0=Mon .. 6=Sun)\n",
    "#         is_weekend  (1 if Sat/Sun)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "# Clean up string columns: remove extra spaces and ensure everything is str\n",
    "for col in [\"Product Type\", \"Event Type\", \"User ID\"]:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Parse timestamp column to datetime; invalid parsings become NaT\n",
    "df[\"Time of Event\"] = pd.to_datetime(df[\"Time of Event\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where Time of Event could not be parsed\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"Time of Event\"])\n",
    "after = len(df)\n",
    "\n",
    "print(f\"Dropped {before - after} rows with invalid timestamps.\")\n",
    "print(f\"After timestamp cleaning: {df.shape}\")\n",
    "\n",
    "# Create time-based features\n",
    "df[\"event_date\"] = df[\"Time of Event\"].dt.date\n",
    "df[\"event_hour\"] = df[\"Time of Event\"].dt.hour\n",
    "df[\"event_dow\"] = df[\"Time of Event\"].dt.dayofweek  # 0=Mon..6=Sun\n",
    "df[\"is_weekend\"] = df[\"event_dow\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Reorder columns to keep things organized\n",
    "df = df[\n",
    "    [\n",
    "        \"Product Type\",\n",
    "        \"Event Type\",\n",
    "        \"Time of Event\",\n",
    "        \"event_date\",\n",
    "        \"event_hour\",\n",
    "        \"event_dow\",\n",
    "        \"is_weekend\",\n",
    "        \"User ID\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920274b",
   "metadata": {},
   "source": [
    "### Saving the Cleaned CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# SAVE CLEANED DATASET\n",
    "# ----------------------------------------------------\n",
    "# We save the preprocessed dataset so it can be reused by:\n",
    "#   - other notebooks\n",
    "#   - src/summary_stats.py\n",
    "#   - any DP code in later phases\n",
    "#\n",
    "# The file will be saved as:\n",
    "#   data/processed/telemetry_clean.csv\n",
    "# If you want a different name, change CLEAN_PATH above.\n",
    "# ----------------------------------------------------\n",
    "\n",
    "df.to_csv(CLEAN_PATH, index=False)\n",
    "print(f\"Saved cleaned telemetry data to: {CLEAN_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cf9b7",
   "metadata": {},
   "source": [
    "## 3. Basic Summary Statistics\n",
    "\n",
    "We compute:\n",
    "- Standard descriptive stats (`describe(include=\"all\")`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.describe(include=\"all\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a6135",
   "metadata": {},
   "source": [
    "Lot of $NaN$ values so using different way to calculate summary\n",
    "We compute:\n",
    "- Event counts by product type\n",
    "- Event counts by event type\n",
    "- Daily event volumes\n",
    "- Unique users per product type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef84b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events by Product Type\n",
    "by_product = (\n",
    "    df.groupby(\"Product Type\")\n",
    "      .size()\n",
    "      .rename(\"event_count\")\n",
    "      .reset_index()\n",
    "      .sort_values(\"event_count\", ascending=False)\n",
    ")\n",
    "display(by_product)\n",
    "\n",
    "# Events by Event Type\n",
    "by_event = (\n",
    "    df.groupby(\"Event Type\")\n",
    "      .size()\n",
    "      .rename(\"event_count\")\n",
    "      .reset_index()\n",
    "      .sort_values(\"event_count\", ascending=False)\n",
    ")\n",
    "display(by_event)\n",
    "\n",
    "# Events per day\n",
    "df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n",
    "by_day = (\n",
    "    df.groupby(\"event_date\")\n",
    "      .size()\n",
    "      .rename(\"event_count\")\n",
    "      .reset_index()\n",
    "      .sort_values(\"event_date\")\n",
    ")\n",
    "display(by_day.head())\n",
    "\n",
    "# Unique users per product\n",
    "users_per_product = (\n",
    "    df.groupby(\"Product Type\")[\"User ID\"]\n",
    "      .nunique()\n",
    "      .rename(\"unique_users\")\n",
    "      .reset_index()\n",
    "      .sort_values(\"unique_users\", ascending=False)\n",
    ")\n",
    "display(users_per_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6a96a",
   "metadata": {},
   "source": [
    "### Saving tables as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1809e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# REPORT_DIR is the folder where we collect tabular outputs\n",
    "# (CSV, later maybe JSON) that summarize this dataset.\n",
    "#\n",
    "# These files are useful for:\n",
    "#   - Including in the project report\n",
    "#   - Feeding into future scripts\n",
    "#   - Letting the TA quickly inspect stats without rerunning the notebook\n",
    "# ----------------------------------------------------\n",
    "\n",
    "summary = df.describe(include=\"all\")\n",
    "summary.to_csv(os.path.join(REPORT_DIR, \"telemetry_summary_statistics.csv\"))\n",
    "by_product.to_csv(os.path.join(REPORT_DIR, \"telemetry_event_counts_by_product.csv\"), index=False)\n",
    "by_event.to_csv(os.path.join(REPORT_DIR, \"telemetry_event_counts_by_type.csv\"), index=False)\n",
    "by_day.to_csv(os.path.join(REPORT_DIR, \"telemetry_events_per_day.csv\"), index=False)\n",
    "users_per_product.to_csv(os.path.join(REPORT_DIR, \"telemetry_unique_users_per_product.csv\"), index=False)\n",
    "\n",
    "print(\"Saved summary tables into reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1338bb",
   "metadata": {},
   "source": [
    "## 4. Error Rates and Z-Scores by Product Type\n",
    "\n",
    "We now replicate the analysis described in the project README:\n",
    "\n",
    "1. Count errors per product type  \n",
    "2. Count total events per product type  \n",
    "3. Compute error rate  \n",
    "4. Compute z-score of each product's error rate across all products  \n",
    "\n",
    "Mathematically:\n",
    "\n",
    "- Error count:  \n",
    "  \\[\n",
    "  \\text{ErrorCount}_P = \\sum_i \\mathbf{1}\\{\\text{EventType}_i = \\text{error}, \\text{ProductType}_i = P\\}\n",
    "  \\]\n",
    "\n",
    "- Total count:  \n",
    "  \\[\n",
    "  \\text{TotalCount}_P = \\sum_i \\mathbf{1}\\{\\text{ProductType}_i = P\\}\n",
    "  \\]\n",
    "\n",
    "- Error rate:  \n",
    "  \\[\n",
    "  \\text{ErrorRate}_P = \\frac{\\text{ErrorCount}_P}{\\text{TotalCount}_P}\n",
    "  \\]\n",
    "\n",
    "- Z-score:  \n",
    "  \\[\n",
    "  Z_P = \\frac{\\text{ErrorRate}_P - \\bar{\\text{ErrorRate}}}{\\text{SD}(\\text{ErrorRate})}\n",
    "  \\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error counts per product\n",
    "error_counts = (\n",
    "    df[df[\"Event Type\"] == \"error\"]\n",
    "    .groupby(\"Product Type\")\n",
    "    .size()\n",
    "    .rename(\"Error Count\")\n",
    ")\n",
    "\n",
    "# Total counts per product\n",
    "total_counts = (\n",
    "    df.groupby(\"Product Type\")\n",
    "    .size()\n",
    "    .rename(\"Total Count\")\n",
    ")\n",
    "\n",
    "# Combine\n",
    "err = pd.concat([error_counts, total_counts], axis=1)\n",
    "err[\"Error Count\"] = err[\"Error Count\"].fillna(0).astype(int)\n",
    "err[\"Total Count\"] = err[\"Total Count\"].fillna(0).astype(int)\n",
    "\n",
    "# Error rate\n",
    "err[\"Error Rate\"] = err[\"Error Count\"] / err[\"Total Count\"]\n",
    "\n",
    "# Z-scores (handle degenerate case)\n",
    "if err[\"Error Rate\"].nunique() > 1:\n",
    "    err[\"Error Rate Z-Score\"] = zscore(err[\"Error Rate\"])\n",
    "else:\n",
    "    err[\"Error Rate Z-Score\"] = 0.0\n",
    "\n",
    "# Sort by error rate descending\n",
    "err_sorted = err.sort_values(\"Error Rate\", ascending=False)\n",
    "err_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e6db5f",
   "metadata": {},
   "source": [
    "### Saving the error/zcore tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961567e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# This table is important:\n",
    "#   - It gives the \"ground truth\" error rates and z-scores.\n",
    "#   - Later, the DP mechanism will try to approximate these\n",
    "#     with noisy (private) versions.\n",
    "# ----------------------------------------------------\n",
    "\n",
    "err_sorted.to_csv(os.path.join(REPORT_DIR, \"telemetry_error_rates_zscores.csv\"))\n",
    "print(\"Saved telemetry_error_rates_zscores.csv in reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049a80b",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "We plot:\n",
    "\n",
    "- Event type distribution  \n",
    "- Product type distribution  \n",
    "- Events per day (time series)  \n",
    "- Error rate by product type  \n",
    "- Error rate z-score by product type  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea2de1",
   "metadata": {},
   "source": [
    "### 1. Event type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of the number of events by Event Type\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(by_event[\"Event Type\"], by_event[\"event_count\"])\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Event Type Distribution\")\n",
    "plt.tight_layout()\n",
    "path = os.path.join(VIS_DIR, \"event_type_distribution.png\")\n",
    "plt.savefig(path, dpi=200)\n",
    "plt.show()\n",
    "print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3aa762",
   "metadata": {},
   "source": [
    "### 2. Product type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8788de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of the number of events by Product Type\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(by_product[\"Product Type\"], by_product[\"event_count\"])\n",
    "plt.xlabel(\"Product Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Product Type Distribution\")\n",
    "plt.tight_layout()\n",
    "path = os.path.join(VIS_DIR, \"product_type_distribution.png\")\n",
    "plt.savefig(path, dpi=200)\n",
    "plt.show()\n",
    "print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a4963",
   "metadata": {},
   "source": [
    "### 3. Events Over time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of the number of events by Product Type\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(by_day[\"event_date\"], by_day[\"event_count\"])\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Event Count\")\n",
    "plt.title(\"Events Per Day\")\n",
    "plt.tight_layout()\n",
    "path = os.path.join(VIS_DIR, \"events_over_time.png\")\n",
    "plt.savefig(path, dpi=200)\n",
    "plt.show()\n",
    "print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18225054",
   "metadata": {},
   "source": [
    "### 4. & 5. Error rate and z-score per product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot: error rate by product type\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(err_sorted.index.astype(str), err_sorted[\"Error Rate\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"Error Rate by Product Type\")\n",
    "plt.tight_layout()\n",
    "path = os.path.join(VIS_DIR, \"error_rate_by_product.png\")\n",
    "plt.savefig(path, dpi=200)\n",
    "plt.show()\n",
    "print(f\"Saved: {path}\")\n",
    "\n",
    "# Bar plot: z-score of error rate by product type\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(err_sorted.index.astype(str), err_sorted[\"Error Rate Z-Score\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Z-Score (Error Rate)\")\n",
    "plt.title(\"Error Rate Z-Score by Product Type\")\n",
    "plt.tight_layout()\n",
    "path = os.path.join(VIS_DIR, \"error_rate_zscore_by_product.png\")\n",
    "plt.savefig(path, dpi=200)\n",
    "plt.show()\n",
    "print(f\"Saved: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d77e19",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "- We loaded and cleaned the synthetic telemetry dataset.\n",
    "- We created time-based features for later analysis and modeling.\n",
    "- We computed event frequencies, unique users per product, and daily volumes.\n",
    "- We computed **error rates** and **z-scores** for each product type.\n",
    "- We visualized distributions and time trends.\n",
    "\n",
    "These results form the **non-private ground truth** for later differential privacy experiments, where we will:\n",
    "- Add noise to user-level counts,\n",
    "- Recompute DP error rates and z-scores,\n",
    "- Compare them to these results using $L_\\infty$ error and IOU.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dhruv_Patel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
